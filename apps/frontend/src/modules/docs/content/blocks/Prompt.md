# Prompt Block

The Prompt block is the core of your test case. It defines the instruction sent to the LLM.

## Features

- **Version Control**: Every change to a prompt is tracked.
- **Variable Injection**: Use `{{variable}}` syntax to inject dynamic data.
- **Provider Settings**: Configure specific parameters for each provider (OpenAI, Anthropic).

## Usage

When creating a prompt, focus on clarity and specific instructions. You can test your prompt against multiple models simultaneously.
